{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Con questo Jupyter Notebook voglio mostrare come ho elaborato i dati CAMS relativi al PM10 di cui ho parlato in [questo articolo](https://massimilianomoraca.me/blog/gis/pm10-nord-italia/). I dati grezzi sono in formato NetCDF e di come gestire questo particolare formato dati ne ho parlato in un [altro articolo](https://massimilianomoraca.me/blog/pygis-blog/gestione-di-un-file-netcdf/) che, nemmeno a farlo apposta, è incentrato sui dati CAMS.",
   "id": "4b0b529ee109fcdd"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Prima di iniziare",
   "id": "a63d24fb8b5762a"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Librerie",
   "id": "ea23d15630ea1ee0"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Le librerie Python usate per raggiungere lo scopo sono state diverse e le vedrete di seguito. Una però deve essere menzionata tra tutte [Dask](https://www.dask.org/); senza l'uso di questa librerie non mi sarebbe stato possibile velocizzare i processamenti che, nonostante tutto, sono durati ore.",
   "id": "7f921df49fd23e55"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-28T18:40:36.435013Z",
     "start_time": "2024-04-28T18:40:36.432005Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from pathlib import Path\n",
    "import geopandas as gpd\n",
    "import xarray as xr\n",
    "from xrspatial.zonal import stats\n",
    "from geocube.api.core import make_geocube\n",
    "\n",
    "from pandas import DataFrame\n",
    "from xarray import Dataset, DataArray\n",
    "from geopandas import GeoDataFrame\n",
    "from typing import Union"
   ],
   "id": "baaea5cb592a30a4",
   "outputs": [],
   "execution_count": 9
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Fonti dati",
   "id": "2500e12e88e0876"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "I dati del PM10 dal 2013 allo scorso marzo sono il perno di questa analisi a cui ho associato i dati vettoriali dell'ISTAT delle province target(quelle che ricadono nelle regioni con codice da 1 a 11) e sulla popolazione per cella censuaria. Dopo aver scaricato i dati CAMS li ho preprocessati in modo da avere un file `.nc` per anno.",
   "id": "9b6a9254ea2e200"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-28T18:40:27.269484Z",
     "start_time": "2024-04-28T18:40:27.264644Z"
    }
   },
   "cell_type": "code",
   "source": [
    "nc_data_path = Path(\"/home/max/Desktop/pianura_padana/processed/netcdf\")\n",
    "\n",
    "nc_files = list(nc_data_path.glob(\"*.nc\"))\n",
    "\n",
    "nc_files"
   ],
   "id": "2764ba1e774322e8",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PosixPath('/home/max/Desktop/pianura_padana/processed/netcdf/particulate_matter_10um-2021-forecasts.nc'),\n",
       " PosixPath('/home/max/Desktop/pianura_padana/processed/netcdf/particulate_matter_10um-2017-reanalyses.nc'),\n",
       " PosixPath('/home/max/Desktop/pianura_padana/processed/netcdf/particulate_matter_10um-2020-reanalyses.nc'),\n",
       " PosixPath('/home/max/Desktop/pianura_padana/processed/netcdf/particulate_matter_10um-2014-reanalyses.nc'),\n",
       " PosixPath('/home/max/Desktop/pianura_padana/processed/netcdf/particulate_matter_10um-2013-reanalyses.nc'),\n",
       " PosixPath('/home/max/Desktop/pianura_padana/processed/netcdf/particulate_matter_10um-2016-reanalyses.nc'),\n",
       " PosixPath('/home/max/Desktop/pianura_padana/processed/netcdf/particulate_matter_10um-2023-forecasts.nc'),\n",
       " PosixPath('/home/max/Desktop/pianura_padana/processed/netcdf/particulate_matter_10um-2019-reanalyses.nc'),\n",
       " PosixPath('/home/max/Desktop/pianura_padana/processed/netcdf/particulate_matter_10um-2015-reanalyses.nc'),\n",
       " PosixPath('/home/max/Desktop/pianura_padana/processed/netcdf/particulate_matter_10um-2018-reanalyses.nc'),\n",
       " PosixPath('/home/max/Desktop/pianura_padana/processed/netcdf/particulate_matter_10um-2022-forecasts.nc'),\n",
       " PosixPath('/home/max/Desktop/pianura_padana/processed/netcdf/particulate_matter_10um-2024-forecasts.nc')]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-28T18:45:02.231282Z",
     "start_time": "2024-04-28T18:45:02.077211Z"
    }
   },
   "cell_type": "code",
   "source": [
    "target_zones_boundaries = Path(\"/home/max/Desktop/DEV/DrakoNotebook/open_dataset/Limiti01012023_g/ProvCM01012023_g/ProvCM01012023_g_WGS84.shp\")\n",
    "\n",
    "target_zones = gpd.read_file(target_zones_boundaries)\n",
    "target_zones = target_zones[target_zones['COD_REG'].isin(list(range(1, 12)))]\n",
    "target_zones = target_zones.to_crs(4326).sort_values('DEN_UTS')\n",
    "\n",
    "target_zones"
   ],
   "id": "810ef946770fba9a",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "     COD_RIP  COD_REG  COD_PROV  COD_CM  COD_UTS              DEN_PROV  \\\n",
       "5          1        1         6       0        6           Alessandria   \n",
       "41         3       11        42       0       42                Ancona   \n",
       "6          1        2         7       0        7                 Aosta   \n",
       "50         3        9        51       0       51                Arezzo   \n",
       "43         3       11        44       0       44         Ascoli Piceno   \n",
       "..       ...      ...       ...     ...      ...                   ...   \n",
       "26         2        5        27     227      227                     -   \n",
       "102        1        1       103       0      103  Verbano-Cusio-Ossola   \n",
       "1          1        1         2       0        2              Vercelli   \n",
       "22         2        5        23       0       23                Verona   \n",
       "23         2        5        24       0       24               Vicenza   \n",
       "\n",
       "      DEN_CM               DEN_UTS SIGLA             TIPO_UTS    Shape_Area  \\\n",
       "5          -           Alessandria    AL            Provincia  3.560310e+09   \n",
       "41         -                Ancona    AN            Provincia  1.961932e+09   \n",
       "6          -                 Aosta    AO            Provincia  3.258838e+09   \n",
       "50         -                Arezzo    AR            Provincia  3.233326e+09   \n",
       "43         -         Ascoli Piceno    AP            Provincia  1.229268e+09   \n",
       "..       ...                   ...   ...                  ...           ...   \n",
       "26   Venezia               Venezia    VE  Citta metropolitana  2.473732e+09   \n",
       "102        -  Verbano-Cusio-Ossola    VB            Provincia  2.262145e+09   \n",
       "1          -              Vercelli    VC            Provincia  2.082097e+09   \n",
       "22         -                Verona    VR            Provincia  3.096255e+09   \n",
       "23         -               Vicenza    VI            Provincia  2.720772e+09   \n",
       "\n",
       "                                              geometry  \n",
       "5    POLYGON ((8.40549 45.20148, 8.41749 45.19846, ...  \n",
       "41   POLYGON ((13.21155 43.72501, 13.21979 43.71770...  \n",
       "6    POLYGON ((7.58857 45.97075, 7.58981 45.97073, ...  \n",
       "50   MULTIPOLYGON (((12.21800 43.60394, 12.21816 43...  \n",
       "43   POLYGON ((13.78663 43.07104, 13.79679 43.06211...  \n",
       "..                                                 ...  \n",
       "26   POLYGON ((12.79994 45.82573, 12.80158 45.82316...  \n",
       "102  POLYGON ((8.44976 46.46176, 8.46176 46.45081, ...  \n",
       "1    POLYGON ((8.20447 45.93567, 8.21365 45.92490, ...  \n",
       "22   POLYGON ((10.88379 45.77281, 10.88301 45.77202...  \n",
       "23   POLYGON ((11.53891 46.01330, 11.54452 46.01176...  \n",
       "\n",
       "[64 rows x 12 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>COD_RIP</th>\n",
       "      <th>COD_REG</th>\n",
       "      <th>COD_PROV</th>\n",
       "      <th>COD_CM</th>\n",
       "      <th>COD_UTS</th>\n",
       "      <th>DEN_PROV</th>\n",
       "      <th>DEN_CM</th>\n",
       "      <th>DEN_UTS</th>\n",
       "      <th>SIGLA</th>\n",
       "      <th>TIPO_UTS</th>\n",
       "      <th>Shape_Area</th>\n",
       "      <th>geometry</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>Alessandria</td>\n",
       "      <td>-</td>\n",
       "      <td>Alessandria</td>\n",
       "      <td>AL</td>\n",
       "      <td>Provincia</td>\n",
       "      <td>3.560310e+09</td>\n",
       "      <td>POLYGON ((8.40549 45.20148, 8.41749 45.19846, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>3</td>\n",
       "      <td>11</td>\n",
       "      <td>42</td>\n",
       "      <td>0</td>\n",
       "      <td>42</td>\n",
       "      <td>Ancona</td>\n",
       "      <td>-</td>\n",
       "      <td>Ancona</td>\n",
       "      <td>AN</td>\n",
       "      <td>Provincia</td>\n",
       "      <td>1.961932e+09</td>\n",
       "      <td>POLYGON ((13.21155 43.72501, 13.21979 43.71770...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>Aosta</td>\n",
       "      <td>-</td>\n",
       "      <td>Aosta</td>\n",
       "      <td>AO</td>\n",
       "      <td>Provincia</td>\n",
       "      <td>3.258838e+09</td>\n",
       "      <td>POLYGON ((7.58857 45.97075, 7.58981 45.97073, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>51</td>\n",
       "      <td>0</td>\n",
       "      <td>51</td>\n",
       "      <td>Arezzo</td>\n",
       "      <td>-</td>\n",
       "      <td>Arezzo</td>\n",
       "      <td>AR</td>\n",
       "      <td>Provincia</td>\n",
       "      <td>3.233326e+09</td>\n",
       "      <td>MULTIPOLYGON (((12.21800 43.60394, 12.21816 43...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>3</td>\n",
       "      <td>11</td>\n",
       "      <td>44</td>\n",
       "      <td>0</td>\n",
       "      <td>44</td>\n",
       "      <td>Ascoli Piceno</td>\n",
       "      <td>-</td>\n",
       "      <td>Ascoli Piceno</td>\n",
       "      <td>AP</td>\n",
       "      <td>Provincia</td>\n",
       "      <td>1.229268e+09</td>\n",
       "      <td>POLYGON ((13.78663 43.07104, 13.79679 43.06211...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>27</td>\n",
       "      <td>227</td>\n",
       "      <td>227</td>\n",
       "      <td>-</td>\n",
       "      <td>Venezia</td>\n",
       "      <td>Venezia</td>\n",
       "      <td>VE</td>\n",
       "      <td>Citta metropolitana</td>\n",
       "      <td>2.473732e+09</td>\n",
       "      <td>POLYGON ((12.79994 45.82573, 12.80158 45.82316...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>103</td>\n",
       "      <td>0</td>\n",
       "      <td>103</td>\n",
       "      <td>Verbano-Cusio-Ossola</td>\n",
       "      <td>-</td>\n",
       "      <td>Verbano-Cusio-Ossola</td>\n",
       "      <td>VB</td>\n",
       "      <td>Provincia</td>\n",
       "      <td>2.262145e+09</td>\n",
       "      <td>POLYGON ((8.44976 46.46176, 8.46176 46.45081, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>Vercelli</td>\n",
       "      <td>-</td>\n",
       "      <td>Vercelli</td>\n",
       "      <td>VC</td>\n",
       "      <td>Provincia</td>\n",
       "      <td>2.082097e+09</td>\n",
       "      <td>POLYGON ((8.20447 45.93567, 8.21365 45.92490, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>23</td>\n",
       "      <td>0</td>\n",
       "      <td>23</td>\n",
       "      <td>Verona</td>\n",
       "      <td>-</td>\n",
       "      <td>Verona</td>\n",
       "      <td>VR</td>\n",
       "      <td>Provincia</td>\n",
       "      <td>3.096255e+09</td>\n",
       "      <td>POLYGON ((10.88379 45.77281, 10.88301 45.77202...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>24</td>\n",
       "      <td>0</td>\n",
       "      <td>24</td>\n",
       "      <td>Vicenza</td>\n",
       "      <td>-</td>\n",
       "      <td>Vicenza</td>\n",
       "      <td>VI</td>\n",
       "      <td>Provincia</td>\n",
       "      <td>2.720772e+09</td>\n",
       "      <td>POLYGON ((11.53891 46.01330, 11.54452 46.01176...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>64 rows × 12 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 14
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Funzioni custom",
   "id": "731b549ac7c83ca5"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Un'altra attività importante è stata quella legata allo sviluppo di funzioni custom che mi hanno consentito di ottimizzare il lavoro. Alcune di esse sono entrate a far parte del mio personale package Python che ho sviluppato negli anni per l'analisi dei dati satellitari e le ho quindi un po' più \"ingegnerizzate\":",
   "id": "9421c729e1bcaa17"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# def read_scientific_dataset(\n",
    "#         input_data: Union[str, Path],\n",
    "#         engine: str = \"netcdf4\",\n",
    "#         mask_layer: GeoDataFrame = None,\n",
    "#         parallel: bool = False\n",
    "# ) -> Dataset:\n",
    "#     \"\"\"Read netCDF, Zarr, h5netcdf, scipy file format and return a Dataset.\n",
    "# \n",
    "#     Args:\n",
    "#         input_data: Union[str, Path]\n",
    "#         engine: str\n",
    "#         mask_layer: GeoDataFrame\n",
    "#         parallel: bool\n",
    "# \n",
    "#     Returns:\n",
    "#         Dataset\n",
    "#     \"\"\"\n",
    "#     if parallel:\n",
    "#         data = xr.open_mfdataset(\n",
    "#             paths=input_data,\n",
    "#             engine=engine,\n",
    "#             decode_coords=\"all\",\n",
    "#             parallel=True\n",
    "#         )\n",
    "#     else:\n",
    "#         data = xr.open_dataset(\n",
    "#             filename_or_obj=input_data,\n",
    "#             engine=engine,\n",
    "#             decode_coords=\"all\"\n",
    "#         )\n",
    "#     data.rio.write_crs(4326, inplace=True)\n",
    "# \n",
    "#     if mask_layer is not None:\n",
    "# \n",
    "#         # Make selection mask\n",
    "#         bounds = mask_layer.bounds.squeeze()\n",
    "#         lon_min = round(bounds[\"minx\"], 0) - 1\n",
    "#         lon_max = round(bounds[\"maxx\"], 0)\n",
    "#         lat_min = round(bounds[\"miny\"], 0) - 1\n",
    "#         lat_max = round(bounds[\"maxy\"], 0)\n",
    "# \n",
    "#         # Apply mask\n",
    "#         latitude_slice = slice(lat_min, lat_max)\n",
    "#         longitude_slice = slice(lon_min, lon_max)\n",
    "# \n",
    "#         data = data.sel(lat=latitude_slice, lon=longitude_slice)\n",
    "# \n",
    "#     return data\n",
    "# \n",
    "# \n",
    "# def zonal_statistics(\n",
    "#         vector_data: GeoDataFrame,\n",
    "#         ref_col: str,\n",
    "#         raster_data: DataArray,\n",
    "#         output_file_path: Path = None,\n",
    "#         output_format: str = None,\n",
    "#         output_file_name: str = 'zonal_statistics'\n",
    "# ) -> Union[DataFrame, Path]:\n",
    "#     \"\"\"Calculate zonal statistics.\n",
    "# \n",
    "#     Args:\n",
    "#         vector_data: GeoDataFrame.\n",
    "#         ref_col: str. Column with data to rasterize.\n",
    "#         raster_data: DataArray.\n",
    "#         output_file_path: str.\n",
    "#         output_format: str. Accepted csv, xlsx or json\n",
    "#         output_file_name: str.\n",
    "# \n",
    "#     Returns:\n",
    "#         Union[GeoDataFrame, Path]\n",
    "# \n",
    "#     Raises:\n",
    "#         Not supported file format. Must be csv, xlsx or json.\n",
    "#     \"\"\"\n",
    "#     # Check if vector and raster has same EPSG\n",
    "#     if str(raster_data.rio.crs).lower() != str(vector_data.crs):\n",
    "#         raster_data = raster_data.rio.reproject(vector_data.crs)\n",
    "# \n",
    "#     # Drop raster band. Raster and rasterized vector must have the same shape.\n",
    "#     raster_data = raster_data.squeeze()\n",
    "# \n",
    "#     # Drop nodata\n",
    "#     raster_data = raster_data.where(raster_data != raster_data.rio.nodata)\n",
    "# \n",
    "#     # Rasterize vector\n",
    "#     rasterized_vector = make_geocube(\n",
    "#         vector_data=vector_data,\n",
    "#         measurements=[ref_col],\n",
    "#         like=raster_data,\n",
    "#     )\n",
    "#     vector_dataarray = rasterized_vector[ref_col]\n",
    "# \n",
    "#     # Compute Zonal Statistics\n",
    "#     compute_zonal_statistics = stats(\n",
    "#         zones=vector_dataarray,\n",
    "#         values=raster_data,\n",
    "#         stats_funcs=[\"mean\", \"max\", \"min\", \"sum\", \"std\", \"count\", \"var\"]\n",
    "#     )\n",
    "# \n",
    "#     # Drop nodata values\n",
    "#     compute_zonal_statistics = compute_zonal_statistics.astype(float).dropna()\n",
    "#     compute_zonal_statistics.rename(columns={\"zone\": ref_col}, inplace=True)\n",
    "# \n",
    "#     if output_file_path is None:\n",
    "#         return compute_zonal_statistics\n",
    "#     else:\n",
    "# \n",
    "#         if output_file_name is not None:\n",
    "#             output_file = output_file_path.joinpath(f\"zonalstatistics.{output_format}\")\n",
    "#         else:\n",
    "#             output_file = output_file_path.joinpath(f\"{output_file_name}.{output_format}\")\n",
    "# \n",
    "#         if output_format == 'json':\n",
    "#             # Save as JSON\n",
    "#             compute_zonal_statistics.to_json(output_file)\n",
    "#         elif output_format == 'csv':\n",
    "#             # Save as CSV\n",
    "#             compute_zonal_statistics.to_csv(output_file)\n",
    "#         elif output_format == 'xlsx':\n",
    "#             # Save as CSV\n",
    "#             compute_zonal_statistics.to_excel(output_file, sheet_name='zonal_statistics')\n",
    "#         else:\n",
    "#             raise Exception('Not supported file format. Must be csv, xlsx or json.')\n",
    "# \n",
    "#         return output_file"
   ],
   "id": "5a35a5fdf43cddb0"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Contenuti\n",
    "- [Aggregazione dei dati](#Aggregazione-dei-dati)\n",
    "- \n",
    "- [Conclusione](#Conclusione)"
   ],
   "id": "c991bf2abddf1a46"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Aggregazione dei dati",
   "id": "7960f7ef4f06fbd"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Lo scopo di questa attività è stato quello di aggregare i dati su base provinciale e di generare un `.csv` per Provincia.",
   "id": "53c4b4534579233f"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "30526912eea3b3dc"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
